---
title: "Debugging Production Issues Like a Pro"
date: "2024.12.04"
tags: [debugging, production, monitoring, troubleshooting]
---

Production bugs are inevitable. What separates good developers from great ones is how quickly and effectively they can diagnose and fix issues when they occur. Here's my systematic approach to production debugging.

## The Debugging Mindset

### Stay Calm and Systematic
When production is on fire, it's easy to panic. Instead:
1. **Take a deep breath** - Panic leads to mistakes
2. **Gather information first** - Don't jump to solutions
3. **Document everything** - You'll need it for the post-mortem
4. **Communicate status** - Keep stakeholders informed

### The Scientific Method
Treat debugging like a science experiment:
1. **Observe** - What exactly is happening?
2. **Hypothesize** - What could be causing this?
3. **Test** - Can you reproduce the issue?
4. **Analyze** - What do the results tell you?
5. **Iterate** - Refine your hypothesis and test again

## Essential Debugging Tools

### Logging and Monitoring
```javascript
// Structured logging example
const logger = require('winston');

logger.info('User login attempt', {
  userId: user.id,
  email: user.email,
  ip: req.ip,
  userAgent: req.get('User-Agent'),
  timestamp: new Date().toISOString()
});

// Add correlation IDs for request tracing
app.use((req, res, next) => {
  req.correlationId = uuidv4();
  res.set('X-Correlation-ID', req.correlationId);
  next();
});
```

### Application Performance Monitoring (APM)
Tools I rely on:
- **Datadog** - Comprehensive monitoring and alerting
- **Sentry** - Error tracking and performance monitoring
- **New Relic** - Application performance insights
- **LogRocket** - Session replay for frontend issues

### Database Monitoring
```sql
-- Check for slow queries
SELECT query, mean_time, calls, total_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

-- Monitor connection counts
SELECT count(*) as connections,
       state,
       application_name
FROM pg_stat_activity
GROUP BY state, application_name;
```

## Common Production Issues

### Memory Leaks
**Symptoms:** Gradual performance degradation, eventual crashes

**Investigation:**
```javascript
// Monitor memory usage
const used = process.memoryUsage();
console.log({
  rss: `${Math.round(used.rss / 1024 / 1024 * 100) / 100} MB`,
  heapTotal: `${Math.round(used.heapTotal / 1024 / 1024 * 100) / 100} MB`,
  heapUsed: `${Math.round(used.heapUsed / 1024 / 1024 * 100) / 100} MB`,
  external: `${Math.round(used.external / 1024 / 1024 * 100) / 100} MB`
});

// Common causes and fixes
// 1. Event listeners not removed
component.addEventListener('scroll', handler);
// Fix: component.removeEventListener('scroll', handler);

// 2. Closures holding references
function createHandler(largeData) {
  return function() {
    // This closure keeps largeData in memory
    console.log('Handler called');
  };
}
// Fix: Don't capture unnecessary variables
```

### Database Performance Issues
**Symptoms:** Slow response times, timeouts

**Investigation checklist:**
```bash
# Check database connections
SELECT * FROM pg_stat_activity WHERE state = 'active';

# Identify blocking queries
SELECT blocked_locks.pid AS blocked_pid,
       blocked_activity.usename AS blocked_user,
       blocking_locks.pid AS blocking_pid,
       blocking_activity.usename AS blocking_user,
       blocked_activity.query AS blocked_statement,
       blocking_activity.query AS current_statement_in_blocking_process
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

### API Rate Limiting Issues
**Symptoms:** 429 errors, degraded performance

**Solution:**
```javascript
// Implement exponential backoff
async function apiCallWithRetry(url, options, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      const response = await fetch(url, options);
      
      if (response.status === 429) {
        const retryAfter = response.headers.get('Retry-After') || Math.pow(2, i);
        await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
        continue;
      }
      
      return response;
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, Math.pow(2, i) * 1000));
    }
  }
}
```

## Debugging Strategies

### Reproduce the Issue
```javascript
// Create a minimal reproduction case
const reproductionSteps = [
  '1. User logs in with email: test@example.com',
  '2. Navigates to /dashboard',
  '3. Clicks on "Export Data" button',
  '4. Error occurs: "Cannot read property of undefined"'
];

// Add debugging information
console.log('Reproduction environment:', {
  nodeVersion: process.version,
  environment: process.env.NODE_ENV,
  timestamp: new Date().toISOString(),
  userAgent: req.get('User-Agent')
});
```

### Binary Search Debugging
When you have a large codebase:
```bash
# Use git bisect to find the problematic commit
git bisect start
git bisect bad HEAD  # Current version is bad
git bisect good v1.2.0  # Last known good version

# Git will checkout commits for you to test
# Mark each as good or bad until you find the culprit
git bisect good  # or git bisect bad
```

### Feature Flag Debugging
```javascript
// Use feature flags to isolate issues
const featureFlags = {
  newPaymentFlow: process.env.ENABLE_NEW_PAYMENT === 'true',
  enhancedLogging: process.env.ENHANCED_LOGGING === 'true'
};

if (featureFlags.enhancedLogging) {
  logger.debug('Payment processing started', { orderId, amount, userId });
}

// Quickly disable problematic features
if (featureFlags.newPaymentFlow) {
  return processPaymentV2(order);
} else {
  return processPaymentV1(order);
}
```

## Prevention Strategies

### Comprehensive Monitoring
```javascript
// Health check endpoint
app.get('/health', async (req, res) => {
  const health = {
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    memory: process.memoryUsage(),
    database: await checkDatabaseConnection(),
    redis: await checkRedisConnection(),
    externalAPIs: await checkExternalServices()
  };
  
  const isHealthy = Object.values(health).every(check => 
    check.status !== 'error'
  );
  
  res.status(isHealthy ? 200 : 503).json(health);
});
```

### Error Boundaries and Graceful Degradation
```javascript
// React Error Boundary
class ErrorBoundary extends React.Component {
  constructor(props) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error) {
    return { hasError: true };
  }

  componentDidCatch(error, errorInfo) {
    // Log error to monitoring service
    Sentry.captureException(error, { extra: errorInfo });
  }

  render() {
    if (this.state.hasError) {
      return <FallbackComponent />;
    }
    return this.props.children;
  }
}

// API graceful degradation
async function getUserData(userId) {
  try {
    return await api.getUser(userId);
  } catch (error) {
    logger.error('Failed to fetch user data', { userId, error });
    // Return cached data or default values
    return getCachedUserData(userId) || getDefaultUserData();
  }
}
```

## Post-Incident Process

### Document Everything
```markdown
# Incident Report: Payment Processing Outage

## Timeline
- 14:30 UTC: First error reports received
- 14:32 UTC: Incident declared, team notified
- 14:45 UTC: Root cause identified (database connection pool exhaustion)
- 15:00 UTC: Fix deployed
- 15:15 UTC: Service fully restored

## Root Cause
Database connection pool was configured for 10 connections but traffic spike required 50+ concurrent connections.

## Resolution
- Increased connection pool size to 50
- Added connection pool monitoring
- Implemented circuit breaker pattern

## Action Items
1. [ ] Add database connection alerts (Owner: @dev-team, Due: Next week)
2. [ ] Load test payment flow (Owner: @qa-team, Due: Next sprint)
3. [ ] Document runbook for similar issues (Owner: @ops-team, Due: This week)
```

## Key Takeaways

1. **Invest in observability** - You can't debug what you can't see
2. **Practice incident response** - Run game days and fire drills
3. **Learn from every incident** - Post-mortems are learning opportunities
4. **Automate common fixes** - Reduce time to resolution
5. **Keep calm under pressure** - Clear thinking leads to faster resolution

Remember: The goal isn't to never have production issuesâ€”it's to resolve them quickly and learn from them. Every bug is an opportunity to make your system more robust.

What's your approach to production debugging? Share your war stories and lessons learned!
